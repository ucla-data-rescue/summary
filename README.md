Introduction
------------

The [End of Term Web Archive](http://digital2.library.unt.edu/nomination/eth2016/about/) is a project to preserve public government websites and data that are at risk of being removed during the transition from one US administration to another.  The Federal government has produced a great many websites and resources, and the process of archiving them takes weeks and months.  The goal of these _data rescue_ efforts is to identify the most urgent cases so that they get archived sooner.  "Urgent cases" are those that the incoming administration may be particularly antagonistic towards.

In this UCLA event, our seeding and sorting goal will be Department of Energy (DOE) sites. We will prioritize (1) Office of Energy Efficiency and Renewable Energy, (2) Office of Science, Energy Information Administration, the (3) Federal Energy Regulatory Commission, and (4) National Renewable Energy Laboratory, in that order.


Summary of the webcrawler
-------------------------

* [Understanding what the Internet Archive webcrawler does](https://docs.google.com/document/d/1PeWefW2toThs-Pbw0CMv2us7wxQI0gRrP1LGuwMp_UQ/edit)

* [Seeding the End of Term crawler's list of URLs to crawl](https://docs.google.com/document/d/1qpuNCmBmu4KcsS_hE2srewcCiP4f9P5cCyDfHmsSAVU/edit)

More information for seeders and sorters
----------------------------------------

The _Seeders and Sorters_ team canvases the resources of a given government agency, identifying important URLs. They sort them by whether their data can be automatically captured by the Internet Archive webcrawler. URLs judged to be possibly crawlable are "nominated" (equivalently, "seeded") using our [Chrome extension](https://chrome.google.com/webstore/detail/nominationtool/abjpihafglmijnkkoppbookfkkanklok) or bookmarklet. This sorting is only provisional: when in doubt seeders mark a URL as possibly not crawlable, and these URLs populate a spreadsheet. 

* [The nomination tool Google Chrome extension](https://chrome.google.com/webstore/detail/nominationtool/abjpihafglmijnkkoppbookfkkanklok)

* [The agency forecasts developed by EDGI](https://envirodatagov.org/agency-forecasts/) &ndash; we are focusing on DOE for seeding, and a set of uncrawlable resources identified by past events

More detail for researchers
---------------------------

_Researchers_ take a closer look at URLs that seeers and sorters flagged as possibly not crawlable.  This activity requires more familiarity with HTML, JavaScript, the types of resources that might be encountered on the web, and how the web works in general.

* [Summary of procedure for researchers](https://github.com/datarefugephilly/workflow/blob/master/research.md)

The complete workflow
---------------------

The two steps above are part of a larger workflow still under active development by several groups.  Currently, the clearest articulation of that workflow is the following documentation developed by the UPenn group:

* [Philly workflow](https://github.com/datarefugephilly/workflow)


Additional details
------------------

* [EDGI EOT toolkit description](https://github.com/edgi-govdata-archiving/eot-sprint-toolkit)

* [FAQs for the Internet Archive's Wayback Machine](http://archive.org/about/faqs.php#The_Wayback_Machine)
